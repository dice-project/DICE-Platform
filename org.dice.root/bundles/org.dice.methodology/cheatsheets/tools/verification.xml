<cheatsheet
      title="Verification Tool">
   <intro>
      <description>This Cheat Sheet describes the methodological steps that the DICE user follows for verifying DICE UML models with D-VerT, the verification tool of the DICE platform.
<br/>
D-VerT is useful for assessing the temporal behavior of a DIA. The validation is carried out at the DTSM level to either:
<br/>
- verify the presence of bottleneck node in a Storm application, or<br/>
- verify the temporal feasibility of a Spark job.</description>
      </intro>
   <item
         dialog="true"
         title="DIA design and verification in practice">
   	<description>First step is to create the UML project and initialize: a <b>Class Diagram</b>, in case you want to model a Storm Topology,
a <b>Class Diagram</b> and an <b>Activity Diagram</b> in case you want to model a Spark Application.</description>
   	<subitem label="Create a new Papyrus UML project.  Select only  &quot;Class diagram&quot; for Storm design. Select both &quot;Activity diagram&quot; (DTSM) and &quot;Class diagram&quot; for (DPIM) for Spark design.am&quot; (DTSM) and &quot;Class diagram&quot; (DPIM) for Spark design;">
   		<command required="false" serialization="org.eclipse.ui.newWizard(newWizardId=org.eclipse.papyrus.uml.diagram.wizards.createproject)"></command></subitem>
   	<subitem
            label="For Storm applications, open the class diagram and instantiate two packages, one for the DPIM model and another for the DTSM model and applies on the packages the DICE::DPIM and the DICE:DTSM UML profiles respectively. Specifically, select the “Core” and the “Storm” metamodels/profile that can be found in the DTSM entry."
            skip="true"></subitem>
    <subitem
          label="For Spark applications, open the activity diagram and instantiate two packages, one for the DPIM model and another for the DTSM model and applies on the packages the DICE::DPIM and the DICE:DTSM UML profiles respectively.  Specifically, select the “Core” and the “Spark” metamodels/profile that can be found in the DTSM entry."
          skip="true">
    </subitem></item>
   <item title="DPIM modeling"><description>In the DPIM package, the user models the high level architecture of the DIA, as a class diagram representing the computations over various data sources. To this end, you need to perform the following steps</description>
   	<subitem label="Instantiate a new class and applies the &lt;&lt;DPIMComputationNode&gt;&gt; stereotype on it"></subitem>
   	<subitem label="Model the data sources, which can be either profiled by using the &lt;&lt;DPIMSourceNode&gt;&gt; of the &lt;&lt;DPIMStorageNode&gt;&gt; stereotypes, depending on the kind of data source"></subitem>
   	<subitem label="Finally, associate the computation nodes to the available data sources."></subitem>
   </item>
   <item
         skip="true"
         title="DTSM Modeling - Intro">
      <description>
         In the DTSM package, the user specifies which technologies implement the various components of the DIA. In particular, the user models the actual implementation of the computations declared in the DPIM, plus all the required technology-specific details.
      </description>
   </item>
   <item title="DTSM modeling - Storm">
   	<description>
A Storm application consists in a DAG composed of two kind of nodes: source nodes, also called <b>spouts</b>, and computation nodes, also called <b>bolts</b>.
Each of these nodes are represented by class instances that are properly annotated and connected by means of associations. &lt;/br&gt;
To design a Storm application follow these steps:
</description>
   	<subitem label="By drag-and-drop from right panel, add to the design all the nodes (Class nodes) defining the application."></subitem>
   	<subitem label="From the bottom panel, select the proper stereotype for each component of the application. The stereotype is chosen according to the kind of the node, that can be either a data source (&lt;&lt;StormSpout&gt;&gt;) or a computational node (&lt;&lt;StormBolt&gt;&gt;)."></subitem>
   	<subitem label="Connect the nodes together through directed associations. Each association defines the subscription relation between two nodes: the subscriber, at the beginning of the arrow, and the subscribed node, at the end of the arrow. "></subitem>
   	<subitem label="The final topology which will be verified with D-VerT."></subitem>
   </item>
   <item
         title="DTSM Modeling - Spark">
      <description>
         A Spark application consists in a DAG whose nodes are the operations performed over data. There are two main kind of operations that are performed: <b>transformations</b> and <b>actions</b>.
Each node (operation) is represented as a properly annotated opaque action in the activity diagram.
&lt;/br&gt;
To design a Spark application, follow these steps:
      </description>
      <subitem
            label="Make sure to have an activity node in the editor (should be added by default when an activity diagram is created). If it is not present, add an activity  node to the editor via drag-and-drop from the right panel.">
      </subitem>
      <subitem
            label="Via drag-and-drop from the right panel, add to the main activity node all the nodes constituting the DAG of operations (Opaque Action nodes).">
      </subitem>
      <subitem
            label="Connect the operation nodes by means of Control Flow edges. Each first operation on a starting RDD must be preceded by a Start Node. The last operation must be followed by an End Node.">
      </subitem>
      <subitem
            label="From the bottom panel, select the proper stereotype for each component of the application. The stereotype is chosen according to the kind of the node: for Opaque Action nodes it can be either a transformation (&lt;&lt;SparkMap&gt;&gt;) or an action (&lt;&lt;SparkReduce&gt;&gt;). Select the  &lt;&lt;SparkScenario&gt;&gt; stereotype  to annotate the main activity.">
      </subitem>
   </item>
   <item title="DTSM Modeling - Specify the stereotype values">
   	<description>Before running the verification tool, specifies the values of the parameters related to the technology implementing the application.</description>
   	<subitem
          label="For Storm applications, select each node and define, in the bottom panel, all the information needed for the verification. The values that are required to verify the topology are the following: parallelism, alpha, sigma, for the bolts; parallelism, averageEmitRate for the spouts."
          skip="true"></subitem>
    <subitem
          label="For Spark applications, select each operation and define, in the bottom panel, all the information needed for the verification. The values that are required to verify the application are the following: duration, MapType, numTasks (optional), for transformations (&lt;&lt;SparkMap&gt;&gt;); duration, ReduceType and numTasks for actions (&lt;&lt;SparkReduce&gt;&gt;);The value that need to set in the main activity node (&lt;&lt;SparkScenario&gt;&gt;) are: nAssignedCores, sparkDefaultParallelism and nAssignedMemory."
          skip="true">
    </subitem>
   </item>
   <item title="Verify the Storm topology with D-VerT" dialog="true">
   	<description>Verify the topology with D-VerT by clicking on the Run configurations button. In “Run configuration”, provide the following informations&quot;:</description>
   	<subitem
   		label="The model to be verified (from the Browse menu)">
   	</subitem>
   	<subitem
   		label="The number of time positions to be used in the verification process (time bound) ">
   	</subitem>
   	<subitem
   		label="The plugin that D-VerT uses to verify the model">
   	</subitem>
   	<subitem
   		label="The bolts that the user wants to test for undesired behaviors.">
   	</subitem>
   </item>
   <item
         title="Verify the Spark applications with D-VerT">
      <description>
         Verify the topology with D-VerT by clicking on the Run configurations button. In “Run configuration”, provide the following informations&quot;:
      </description>
      <subitem
            label="The model to be verified (from the Browse menu)">
      </subitem>
      <subitem
            label="The kind of analysis to be performed (feasibility or boundedness). Only feasibility analysis is currently supported.">
      </subitem>
      <subitem
            label="The deadline against which perform the analysis.">
      </subitem>
      <subitem
            label="The number of time positions to be used in the verification process (time bound)">
      </subitem>
   </item>
   <item title="Run D-VerT and monitor verification tasks running">
   	<description>Run D-VerT and monitor running on the server in the D-VerT dashboard. The following informations are available:</description>
   	<subitem
          label="The result of the verification. For Storm the result is SAT if anomalies are observed, otherwise UNSAT. For the feasibility analysis of Spark applications, the result is either FEASIBLE or UNFEASIBLE. For boundedness analysis of Spark applications, the result is either BOUNDED or NOT BOUNDED."></subitem>
   	<subitem 
   	label="In case of SAT  (or, respectively FEASIBLE and NOT BOUNDED), the output trace produced by the model-checker shows the temporal evolution of all the model elements in detail and the graphical representation of the verification outcome shows the anomalies (Storm bottleneck analysis and Spark boundedness analysis) or a feasible trace (Spark feasibility analysis) for a qualitative inspection.">
   	</subitem>
   	</item>

</cheatsheet>
